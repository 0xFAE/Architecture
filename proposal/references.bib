%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%         references.bib
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{samira-ISCA18,
	author = {Ajorpaz, Samira Mirbagher and Garza, Elba and Jindal, Sangam and Jim\'{e}nez, Daniel A.},
	title = {Exploring Predictive Replacement Policies for Instruction Cache and Branch Target Buffer},
	year = {2018},
	isbn = {9781538659847},
	publisher = {IEEE Press},
	url = {https://doi.org/10.1109/ISCA.2018.00050},
	doi = {10.1109/ISCA.2018.00050},
	abstract = {Modern processors support instruction fetch with the instruction cache (I-cache) and branch target buffer (BTB). Due to timing and area constraints, the I-cache and BTB must efficiently make use of their limited capacities. Blocks in the I-cache or entries in the BTB that have low potential for reuse should be replaced by more useful blocks/entries. This work explores predictive replacement policies based on reuse prediction that can be applied to both the I-cache and BTB.Using a large suite of recently released industrial traces, we show that predictive replacement policies can reduce misses in the I-cache and BTB. We introduce Global History Reuse Prediction (GHRP), a replacement technique that uses the history of past instruction addresses and their reuse behaviors to predict dead blocks in the I-cache and dead entries in the BTB.This paper describes the effectiveness of GHRP as a dead block replacement and bypass optimization for both the I-cache and BTB. For a 64KB set-associative I-cache with a 64B block size, GHRP lowers the I-cache misses per 1000 instructions (MPKI) by an average of 18% over the least-recently-used (LRU) policy on a set of 662 industrial workloads, performing significantly better than Static Re-reference Interval Prediction (SRRIP) [1] and Sampling Dead Block Prediction (SDBP)[2]. For a 4K-entry BTB, GHRP lowers MPKI by an average of 30% over LRU, 23% over SRRIP, and 29% over SDBP.},
	booktitle = {Proceedings of the 45th Annual International Symposium on Computer Architecture},
	pages = {519–532},
	numpages = {14},
	location = {Los Angeles, California},
	series = {ISCA '18}
}

@inproceedings{cbp-5,
	journal = {The Journal of Instruction-Level Parallelism}, 
	title = {The 5th JILP Championship Branch Prediction Competition (CBP-5)}, 
	url = {https://www.jilp.org/cbp2016}, 
	year = {2016}
}

@ARTICLE {smith-1985,
	author = {J. Smith and J. Goodman},
	journal = {IEEE Transactions on Computers},
	title = {Instruction Cache Replacement Policies and Organizations},
	year = {1985},
	volume = {34},
	number = {03},
	issn = {1557-9956},
	pages = {234-241},
	keywords = {set-associative;cache memories;direct-mapped;fully associative;loop model;memory organization;replacement algorithms},
	doi = {10.1109/TC.1985.1676566},
	publisher = {IEEE Computer Society},
	address = {Los Alamitos, CA, USA},
	month = {mar}
}

@article{perleberg-1993,
	author = {Perleberg, C. H. and Smith, A. J.},
	title = {Branch Target Buffer Design and Optimization},
	year = {1993},
	issue_date = {April 1993},
	publisher = {IEEE Computer Society},
	address = {USA},
	volume = {42},
	number = {4},
	issn = {0018-9340},
	url = {https://doi.org/10.1109/12.214687},
	doi = {10.1109/12.214687},
	abstract = {A branch target buffer (BTB) can reduce the performance penalty of branches in pipelined processors by predicting the path of the branch and caching information used by the branch. Two major issues in the design of BTBs that achieves maximum performance with a limited number of bits allocated to the BTB implementation are discussed. The first is BTB management. A method for discarding branches from the BTB is examined. This method discards the branch with the smallest expected value for improving performance; it outperforms the least recently used (LRU) strategy by a small margin, at the cost of additional complexity. The second issue is the question of what information to store in the BTB. A BTB entry can consist of one or more of the following: branch tag, prediction information, the branch target address, and instructions at the branch target. Various BTB designs, with one or more of these fields, are evaluated and compared.},
	journal = {IEEE Trans. Comput.},
	month = apr,
	pages = {396–412},
	numpages = {17},
	keywords = {complexity, least recently used, performance penalty, instruction sets, branch target address, pipelined processors, branch target buffer design, buffer storage, caching, prediction information, branches, pipeline processing., instructions, optimization, branch tag}
}
